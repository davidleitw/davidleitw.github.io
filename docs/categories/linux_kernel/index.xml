<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>linux_kernel - Category - davidLei</title>
        <link>https://davidleitw.github.io/categories/linux_kernel/</link>
        <description>linux_kernel - Category - davidLei</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>davidleitw@gmail.com (davidlei)</managingEditor>
            <webMaster>davidleitw@gmail.com (davidlei)</webMaster><lastBuildDate>Tue, 28 Jun 2022 04:16:48 &#43;0800</lastBuildDate><atom:link href="https://davidleitw.github.io/categories/linux_kernel/" rel="self" type="application/rss+xml" /><item>
    <title>Linux file descriptor 理解</title>
    <link>https://davidleitw.github.io/posts/fd/</link>
    <pubDate>Tue, 28 Jun 2022 04:16:48 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://davidleitw.github.io/posts/fd/</guid>
    <description><![CDATA[前言 file descriptor 常被簡稱為 fd, 在學習 Linux 的過程中，會看到很多 system call 藉由 fd 來操作文件或抽象資源，像是 network programming 中呼叫 socket 之後會使用回傳的 socket fd 去進行後續的操作，或者 I/O 領域的 epoll 同樣在呼叫 epoll_create 之後會回傳 fd，此後對於 epoll 相關的操作都要把 fd 當作第一個參數傳入。
在 Linux 中常常會看到 fd 的身影，但一直沒有花時間去深入了解這個 fd 底層的實現，只是有模糊的概念而已，所以趁這個機會來整理一篇筆記，紀錄一下。
在 File descriptor 中可以簡單看一下，究竟在 Linux 中有多少 system call 使用了 File descriptor 的概念，就知道 fd 在 Linux 中的重要性了。
Everything is a file Linux 秉持著 UNIX 哲學 Everything is a file，這個概念的好處是可以用一組通用的 Interface 來操作不同資源，在資源跟使用者之間加上一層抽象層，進而延伸出 Universal I/O Model 的概念。]]></description>
</item><item>
    <title>Linux waitqueue 原始碼解讀</title>
    <link>https://davidleitw.github.io/posts/linux_wake_queue1/</link>
    <pubDate>Sat, 08 Jan 2022 03:12:53 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://davidleitw.github.io/posts/linux_wake_queue1/</guid>
    <description><![CDATA[本文章環境基於 Linux v4.14.259
概述 waitqueue 如同其名，是 kernel 中管理一些在等待資源的 task 的資料結構，在 task 還沒辦法獲得資源時，會先將其放入 waitqueue 等待特定條件或者資源準備就緒才會把該 task 喚醒。
waitqueue 有定義兩種資料結構
wait_queue_head: waitqueue 的 head wait_queue_entry: 來表示每個在 waitqueue 的元素 waitqueue 所有的實現都是基於 kernel 內建的 double circular linked list 來實現，所以本身的設計非常簡潔。 以下為 waitqueue 基本的 data struct 定義，位在 /include/linux/wait.h
wait_queue_head_t struct wait_queue_head { spinlock_t	lock; // 自旋鎖 struct list_head	head; // 指向 prev, next entry. }; typedef struct wait_queue_head wait_queue_head_t; 初始化 waitqueue 要建立新的 waitqueue，必須要先初始化 wait_queue_head_t 結構，透過 init_waitqueue_head，定義如下]]></description>
</item><item>
    <title>Linux schedule 原始碼解讀</title>
    <link>https://davidleitw.github.io/posts/linux_get_context_switch/</link>
    <pubDate>Fri, 07 Jan 2022 03:12:53 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://davidleitw.github.io/posts/linux_get_context_switch/</guid>
    <description><![CDATA[本文章環境基於 Linux v4.14.259
第一次 trace 整個排程的流程，kernel 真的是個大坑，有很多概念都還不熟，只能整理大概的流程，具體很多 function 的作用都沒辦法很好的說明，希望之後可以多閱讀 source code，把相關的知識慢慢補齊，拼湊成完整的知識。
schedule 要 trace 排程器要先找到 schedule 的入口，定義在 kernel/sched/core.c，函式定義如下
asmlinkage __visible void __sched schedule(void) { struct task_struct *tsk = current; // 避免 deadlock sched_submit_work(tsk); do { // 排程本身無法搶佔，等排程完畢再開啟 preempt_disable(); __schedule(false); // 排程完成，開啟搶佔功能 sched_preempt_enable_no_resched(); } while (need_resched()); // 檢查是不是被設置 TIF_NEED_RESCHED，如果被設置就重新排程 } EXPORT_SYMBOL(schedule); sched_submit_work static inline void sched_submit_work(struct task_struct *tsk) { if (!tsk-&gt;state || tsk_is_pi_blocked(tsk)) return; /* * If we are going to sleep and we have plugged IO queued, * make sure to submit it to avoid deadlocks.]]></description>
</item><item>
    <title>Linux fork() 底層實作流程整理</title>
    <link>https://davidleitw.github.io/posts/linux_fork_01/</link>
    <pubDate>Wed, 05 Jan 2022 00:12:53 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://davidleitw.github.io/posts/linux_fork_01/</guid>
    <description><![CDATA[本文章環境基於 Linux v4.14.259
因為作業需要在 task_struct 中加入 counter 並且觀察排程器的行為，所以在這邊寫一份筆記來紀錄一下在 linux 中一個 process 建立的時候在哪裡初始化，從 fork() 開始慢慢 trace 下去。
在 Linux 中並沒有明確區分 process 跟 thread, task_struct 可以根據創立條件的不同代表 process 或者 thread。
從實作的角度看可以有以下幾種 system call 建立新的 task_struct:
建立 user process: fork, vfork, clone 建立 kernel thread: kernel_thread, kthread_create 以上這些 API 最後都會呼叫 /kernel/fork.c 中的 _do_fork 來進行 create task_struct 的操作，只是會根據給的參數不同，來決定建立出來的 task_struct 的性質，以上幾個 system call 的差別也可以參考 The difference between fork(), vfork(), exec() and clone()
但是如果看最新幾版的 kernel source code 會發現怎麼樣都沒辦法找到 _do_fork 這個 function 了，仔細找了一下原因，發現在 linux v5.]]></description>
</item></channel>
</rss>
